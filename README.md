# MOSA: Music mOtion and Semantic Annotation dataset

![alt text](https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset/blob/main/figure/dataset.png)

MOSA dataset is a large-scale music dataset containing 742 professional piano and violin solo music performances with 23 musicians (> 30 hours, and > 570 K notes). This dataset features following types of data
- High-quality 3-D motion capture data
-  audio recordings
- manual semantic annotations


# 1. 3-D motion capture data
The 3-D motion capture data in this dataset are recorded using Qualisys and Vicon 3-D motion capture system. The original coordinates of the body/instrument markers on the x-, y-, and z- axes are provided. The body marker placement
follows the Plug-In Gait Full-body model in Visual-3D's official documention.

![alt text](https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset/blob/main/figure/mocap.png)

